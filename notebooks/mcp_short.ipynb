{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Model Context Protocol (MCP)\n",
    "**For Computational Linguistics & NLP Students**\n",
    "\n",
    "## 1. What is MCP? (5 minutes)\n",
    "\n",
    "### The Problem: The M×N Integration Nightmare\n",
    "\n",
    "Imagine you want Claude, ChatGPT, and a local Llama model to all access your annotated corpus. Traditionally, you'd need to write **3 separate integrations** - one for each model's specific API.\n",
    "\n",
    "Now imagine you add 2 more tools (a sentiment analyzer and a dependency parser). Now you need **3 × 3 = 9 integrations**!\n",
    "\n",
    "### The Solution: MCP as a Universal Standard\n",
    "\n",
    "**The Model Context Protocol (MCP)** is like **USB-C for AI**:\n",
    "- **USB-C**: One port works with any device (mouse, keyboard, drive)\n",
    "- **MCP**: One server works with any AI client (Claude, Cursor, custom apps)\n",
    "\n",
    "Write your corpus server **once**, and any MCP-compatible AI can use it.\n",
    "\n",
    "<img src=\"https://mintcdn.com/mcp/bEUxYpZqie0DsluH/images/mcp-simple-diagram.png?fit=max&auto=format&n=bEUxYpZqie0DsluH&q=85&s=35268aa0ad50b8c385913810e7604550\" alt=\"MCP Diagram\" width=\"800\"/>\n",
    "\n",
    "<img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1761561683902/6b0f2299-041e-4ef4-a6ce-726899c52fbf.png\" alt=\"MCP USB-C Analogy\" width=\"600\"/>\n",
    "\n",
    "### Three Simple Primitives\n",
    "\n",
    "MCP has just three building blocks:\n",
    "\n",
    "1. **Resources**: Data the AI can read (files, database entries, API responses)\n",
    "2. **Tools**: Functions the AI can execute (calculate statistics, run analyses)\n",
    "3. **Prompts**: Templates that guide the AI's use of your server\n",
    "\n",
    "---\n",
    "\n",
    "## 2. MCP vs. REST: A Different Philosophy (5 minutes)\n",
    "\n",
    "As students familiar with REST APIs (like FastAPI), you might wonder: \"Isn't this just another API?\"\n",
    "\n",
    "**No.** MCP represents a fundamental paradigm shift.\n",
    "\n",
    "### The Core Difference\n",
    "\n",
    "| Dimension | REST API | MCP |\n",
    "|-----------|----------|-----|\n",
    "| **Design Philosophy** | **Resource-oriented** (nouns)<br/>\"What data exists?\" | **Action-oriented** (verbs)<br/>\"What can I do?\" |\n",
    "| **Mindset** | **Unopinionated**<br/>\"Here is raw data; you figure out how to use it.\" | **Goal-Oriented**<br/>\"Here are specific tools to help you achieve a task.\" |\n",
    "| **Primary User** | Human developers reading docs | AI agents discovering capabilities |\n",
    "| **Discovery** | Manual: Read OpenAPI/Swagger | Automatic: Server advertises tools |\n",
    "| **Logic Location** | **Client-Side**<br/>The Agent must loop/filter/sort. | **Server-Side**<br/>The Server handles the complexity. |\n",
    "| **Semantics** | Low-level CRUD operations | High-level actions |\n",
    "\n",
    "### Example: The Difference in Practice\n",
    "\n",
    "**Task:** Archive all blog posts from 2023\n",
    "\n",
    "**REST approach (what agent must do):**\n",
    "```python\n",
    "# The Agent has to:\n",
    "# 1. Know the endpoint URL schema\n",
    "# 2. Handle pagination (loops)\n",
    "# 3. Handle JSON formatting manually\n",
    "\n",
    "page = 1\n",
    "while True:\n",
    "    data = requests.get(f\"/api/blogs?year=2023&page={page}\").json()\n",
    "    if not data: break\n",
    "    for post in data:\n",
    "         # Agent must know specific field names ('id', 'status')\n",
    "         requests.put(f\"/api/blogs/{post['id']}\", json={\"status\": \"archived\"})\n",
    "    page += 1\n",
    "```\n",
    "Risk: The Agent might hallucinate the loop logic or mess up the ID format.\n",
    "\n",
    "**MCP Approach (The \"Contractor\" Method - Turnkey Service): The Server anticipates the goal and provides a high-level tool.**\n",
    "```python\n",
    "# One high-level action\n",
    "# The Agent simply calls the tool:\n",
    "await session.call_tool(\"archive_old_posts\", arguments={\"year\": 2023})\n",
    "```\n",
    "✓ Single operation, atomic, server handles complexity.\n",
    "\n",
    "### Why This Matters for Linguistics\n",
    "\n",
    "When building NLP tools, you want agents to think:\n",
    "- \"Annotate this text with POS tags\" ✓\n",
    "\n",
    "Not:\n",
    "- \"GET the text, POST it to the tagger, PUT the results back\" ✗\n",
    "\n",
    "MCP lets you expose **linguistic operations** rather than **data CRUD**.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. How MCP Works (Simple Version)\n",
    "\n",
    "### The Architecture (High-Level)\n",
    "\n",
    "```\n",
    "┌─────────────────┐\n",
    "│   AI Client     │  (Claude, Cursor, etc.)\n",
    "│   (The Host)    │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         │ JSON-RPC messages\n",
    "         │ over stdio/HTTP/SSE\n",
    "         │\n",
    "┌────────▼────────┐\n",
    "│   MCP Server    │  (Your linguistic tools)\n",
    "│                 │\n",
    "│  • Tools        │  calculate_ttr()\n",
    "│  • Resources    │  corpus://text/123\n",
    "│  • Prompts      │  analyze_complexity()\n",
    "└─────────────────┘\n",
    "```\n",
    "\n",
    "### The Contrast: Connecting to Tools\n",
    "\n",
    "**Option A: The REST Handshake (Manual Reality)**\n",
    "\n",
    "1.  **Connection**: Developer finds API documentation URL, hardcodes API keys, and initializes a generic HTTP client.\n",
    "2.  **Discovery (The Hard Part)**: Developer **manually reads** 50 pages of Swagger/OpenAPI documentation, selects relevant endpoints, and writes a custom \"System Prompt\" to explain how `GET /corpus` works to the AI.\n",
    "3.  **Usage**: AI outputs raw JSON; Developer writes `try/except` blocks to parse it and make the HTTP call.\n",
    "4.  **Shutdown**: No protocol. Stateless.\n",
    "\n",
    "**Option B: The MCP Handshake (Automated Reality)**\n",
    "\n",
    "1.  **Connection**: Client connects to server (via command-line process).\n",
    "2.  **Discovery**: Server **automatically** tells client: \"I can do X, Y, Z.\"\n",
    "3.  **Usage**: Client calls tools as needed directly.\n",
    "4.  **Shutdown**: Clean disconnect.\n",
    "\n",
    "**Key insight**: The AI doesn't need to read documentation—the server describes itself\\!\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Demo: A Linguistic Analysis Server (15 minutes)\n",
    "\n",
    "Let's build a simple MCP server for corpus analysis using `fastmcp` (think \"FastAPI for MCP\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "# %pip install fastmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "# Initialize server (like FastAPI's app = FastAPI())\n",
    "mcp = FastMCP(\"LinguistHelper\")\n",
    "\n",
    "# Mock corpus (in reality, this could be a database)\n",
    "CORPUS = {\n",
    "    \"en_sample_01\": \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"en_sample_02\": \"To be, or not to be, that is the question.\",\n",
    "    \"zh_sample_01\": \"學而不思則罔,思而不學則殆。\",\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# RESOURCES: Give AI access to data\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@mcp.resource(\"corpus://list\")\n",
    "def list_texts() -> str:\n",
    "    \"\"\"List all available text IDs in the corpus.\"\"\"\n",
    "    return \"\\n\".join(CORPUS.keys())\n",
    "\n",
    "\n",
    "@mcp.resource(\"corpus://{text_id}\")\n",
    "def get_text(text_id: str) -> str:\n",
    "    \"\"\"Retrieve text content by ID.\"\"\"\n",
    "    if text_id not in CORPUS:\n",
    "        available = \", \".join(CORPUS.keys())\n",
    "        return f\"Error: Text '{text_id}' not found. Available: {available}\"\n",
    "    return CORPUS[text_id]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TOOLS: Give AI computational capabilities\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_ttr(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Type-Token Ratio (TTR) of a text.\n",
    "    TTR = (Unique Words / Total Words)\n",
    "    Higher values indicate greater lexical diversity.\n",
    "\n",
    "    Example: \"the cat sat on the mat\" -> 5/6 = 0.83\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "\n",
    "    tokens = text.lower().split()  # Simple tokenization\n",
    "    types = set(tokens)  # Unique words\n",
    "\n",
    "    return len(types) / len(tokens) if tokens else 0.0\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def count_words(text: str) -> int:\n",
    "    \"\"\"Count total words in text.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def find_longest_word(text: str) -> str:\n",
    "    \"\"\"Find the longest word in the text.\"\"\"\n",
    "    words = text.split()\n",
    "    return max(words, key=len) if words else \"\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PROMPTS: Pre-built workflows for common tasks\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@mcp.prompt()\n",
    "def analyze_complexity(text_id: str) -> str:\n",
    "    \"\"\"Generate a prompt for analyzing text complexity.\"\"\"\n",
    "    return f\"\"\"\n",
    "Please analyze the linguistic complexity of corpus://{text_id}.\n",
    "\n",
    "Steps:\n",
    "1. First, read the text using the corpus://{text_id} resource\n",
    "2. Calculate its Type-Token Ratio using the calculate_ttr tool\n",
    "3. Find the longest word using the find_longest_word tool\n",
    "4. Provide a brief assessment of lexical complexity\n",
    "\n",
    "A TTR above 0.7 typically indicates rich vocabulary.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"✓ MCP Server 'LinguistHelper' initialized!\")\n",
    "print(f\"  Resources: {len(mcp._resource_manager._resources)}\")\n",
    "print(f\"  Tools: {len(mcp._tool_manager._tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "We created three types of capabilities:\n",
    "\n",
    "1. **Resources** (`@mcp.resource`):\n",
    "   - `corpus://list` - Lists available texts\n",
    "   - `corpus://{text_id}` - Retrieves specific text\n",
    "   - Think: \"Things the AI can read\"\n",
    "\n",
    "2. **Tools** (`@mcp.tool`):\n",
    "   - `calculate_ttr()` - Computes lexical diversity\n",
    "   - `count_words()` - Simple word count\n",
    "   - `find_longest_word()` - Finds longest token\n",
    "   - Think: \"Things the AI can do\"\n",
    "\n",
    "3. **Prompts** (`@mcp.prompt`):\n",
    "   - `analyze_complexity()` - Pre-built workflow\n",
    "   - Think: \"Recipes for common tasks\"\n",
    "\n",
    "### How an AI Uses This\n",
    "\n",
    "**User asks:** \"Is en_sample_01 lexically diverse?\"\n",
    "\n",
    "**AI's reasoning:**\n",
    "1. \"I should read the text first\" → Calls `corpus://en_sample_01`\n",
    "2. \"Now calculate diversity\" → Calls `calculate_ttr(text)`\n",
    "3. \"Interpret result\" → Returns: \"Yes, TTR of 0.89 indicates high diversity\"\n",
    "\n",
    "The AI **automatically discovers** these capabilities and chains them together!\n",
    "\n",
    "### Running the Server\n",
    "\n",
    "To actually deploy this:\n",
    "\n",
    "```bash\n",
    "# Save the code above to linguistic_server.py\n",
    "# Then run:\n",
    "fastmcp run linguistic_server.py\n",
    "\n",
    "# Or install in Claude Desktop:\n",
    "# Add to claude_desktop_config.json:\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"linguistic-tools\": {\n",
    "      \"command\": \"python\",\n",
    "      \"args\": [\"-m\", \"fastmcp\", \"run\", \"linguistic_server.py\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Now Claude can use your linguistic tools in any conversation!\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Key Design Principles (3 minutes)\n",
    "\n",
    "### Principle 1: Think Actions, Not CRUD\n",
    "\n",
    "❌ **Bad** (REST-style):\n",
    "```python\n",
    "@mcp.tool()\n",
    "def get_text_data(id: str) -> dict:\n",
    "    \"\"\"Get text data\"\"\"\n",
    "    return database.get(id)\n",
    "\n",
    "@mcp.tool()\n",
    "def update_text_data(id: str, data: dict):\n",
    "    \"\"\"Update text data\"\"\"\n",
    "    database.update(id, data)\n",
    "```\n",
    "\n",
    "✅ **Good** (Action-oriented):\n",
    "```python\n",
    "@mcp.tool()\n",
    "def annotate_with_pos_tags(text_id: str) -> str:\n",
    "    \"\"\"Add part-of-speech tags to a corpus text.\"\"\"\n",
    "    text = corpus.get(text_id)\n",
    "    tagged = pos_tagger.tag(text)\n",
    "    corpus.save_annotation(text_id, \"pos\", tagged)\n",
    "    return tagged\n",
    "```\n",
    "\n",
    "### Principle 2: Encapsulate Domain Logic\n",
    "\n",
    "Don't make the AI orchestrate multiple steps. Give it high-level operations:\n",
    "\n",
    "```python\n",
    "@mcp.tool()\n",
    "def full_linguistic_analysis(text_id: str) -> dict:\n",
    "    \"\"\"Run complete analysis pipeline on a text.\"\"\"\n",
    "    text = corpus.get(text_id)\n",
    "    \n",
    "    return {\n",
    "        \"ttr\": calculate_ttr(text),\n",
    "        \"word_count\": count_words(text),\n",
    "        \"longest_word\": find_longest_word(text),\n",
    "        \"pos_tags\": pos_tag(text),\n",
    "        \"readability\": flesch_reading_ease(text)\n",
    "    }\n",
    "```\n",
    "\n",
    "### Principle 3: Security First\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "@mcp.tool()\n",
    "def query_proprietary_corpus(query: str) -> str:\n",
    "    \"\"\"Search our proprietary database.\"\"\"\n",
    "    # API key stays server-side - AI never sees it!\n",
    "    api_key = os.environ[\"CORPUS_API_KEY\"]\n",
    "    return search_api(query, api_key)\n",
    "```\n",
    "\n",
    "The AI can search, but can't leak credentials.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Why This Matters for Your Research (2 minutes)\n",
    "\n",
    "### Use Cases in Computational Linguistics\n",
    "\n",
    "**1. Corpus Access**\n",
    "```python\n",
    "@mcp.resource(\"wals://feature/{feature_id}\")\n",
    "def get_wals_feature(feature_id: str) -> str:\n",
    "    \"\"\"Access World Atlas of Language Structures.\"\"\"\n",
    "    # Now any AI can query typological databases!\n",
    "```\n",
    "\n",
    "**2. Annotation Pipelines**\n",
    "```python\n",
    "@mcp.tool()\n",
    "def annotate_universal_dependencies(text: str, language: str) -> str:\n",
    "    \"\"\"Parse text and return CoNLL-U format.\"\"\"\n",
    "    # Give LLMs access to linguistic parsers\n",
    "```\n",
    "\n",
    "**3. Fieldwork Tools**\n",
    "```python\n",
    "@mcp.tool()\n",
    "def generate_elicitation_prompt(phenomenon: str) -> str:\n",
    "    \"\"\"Create prompts for linguistic elicitation.\"\"\"\n",
    "    # AI-assisted fieldwork!\n",
    "```\n",
    "\n",
    "### The Big Picture\n",
    "\n",
    "**Before MCP:**\n",
    "- Every AI tool needed custom integration\n",
    "- Researchers duplicated effort\n",
    "- Tools were fragmented\n",
    "\n",
    "**With MCP:**\n",
    "- Write linguistic tools **once**\n",
    "- Works with **any** MCP-compatible AI\n",
    "- Build a **reusable ecosystem** of computational linguistics tools\n",
    "\n",
    "---\n",
    "\n",
    "## Summary: Key Takeaways\n",
    "\n",
    "1. **MCP is USB-C for AI** - one protocol, works everywhere\n",
    "\n",
    "2. **MCP ≠ REST** - It's action-oriented (verbs) not resource-oriented (nouns)\n",
    "\n",
    "3. **Three primitives**: Resources (data), Tools (functions), Prompts (workflows)\n",
    "\n",
    "4. **Design for actions** - Think \"annotate text\" not \"GET/PUT text data\"\n",
    "\n",
    "5. **Security built-in** - Credentials stay server-side, AI can't leak secrets\n",
    "\n",
    "6. **Perfect for linguistics** - Share corpus access, annotation tools, and analysis pipelines\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Try it yourself:**\n",
    "1. Install fastmcp: `pip install fastmcp`\n",
    "2. Save the demo code to `linguistic_server.py`\n",
    "3. Run: `fastmcp run linguistic_server.py`\n",
    "4. Test with Claude Desktop or build your own client\n",
    "\n",
    "**Extend it:**\n",
    "- Add tools for your specific research (dependency parsing, NER, etc.)\n",
    "- Connect to real corpora (Universal Dependencies, your own datasets)\n",
    "- Build prompts for common linguistic analysis tasks\n",
    "\n",
    "**Resources:**\n",
    "- Official docs: https://modelcontextprotocol.io/\n",
    "- fastmcp: https://github.com/jlowin/fastmcp\n",
    "- Examples: https://github.com/modelcontextprotocol/servers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51519c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References and Further Reading\n",
    "\n",
    "### Primary Sources\n",
    "\n",
    "1. **Lee, H. (2025).** \"MCP is not REST API.\" *Personal Blog*.  \n",
    "   https://leehanchung.github.io/blogs/2025/05/17/mcp-is-not-rest-api/  \n",
    "   *Core reading on action-oriented vs resource-oriented design and why wrapping REST as MCP is problematic.*\n",
    "\n",
    "2. **Shivanandhan, M. (2025).** \"MCP vs APIs: What's the Real Difference?\" *freeCodeCamp*.  \n",
    "   https://www.freecodecamp.org/news/mcp-vs-apis-whats-the-real-difference/  \n",
    "   *Accessible introduction to MCP with focus on security and safety benefits.*\n",
    "\n",
    "### Official Documentation\n",
    "\n",
    "3. **Anthropic.** \"Model Context Protocol - Introduction.\"  \n",
    "   https://modelcontextprotocol.io/introduction\n",
    "\n",
    "4. **Anthropic.** \"Model Context Protocol - Transports.\"  \n",
    "   https://modelcontextprotocol.io/docs/concepts/transports  \n",
    "   *Technical details on JSON-RPC 2.0 and transport mechanisms.*\n",
    "\n",
    "5. **Anthropic.** \"Model Context Protocol - Resources.\"  \n",
    "   https://modelcontextprotocol.io/docs/concepts/resources\n",
    "\n",
    "6. **Anthropic.** \"Model Context Protocol - Tools.\"  \n",
    "   https://modelcontextprotocol.io/docs/concepts/tools\n",
    "\n",
    "### Technical Deep Dives\n",
    "\n",
    "7. **Loganathan, P. (2025).** \"MCP - Protocol Mechanics and Architecture.\" *Personal Blog*.  \n",
    "   https://pradeepl.com/blog/model-context-protocol/mcp-protocol-mechanics-and-architecture/  \n",
    "   *Detailed explanation of the three-layer architecture and connection lifecycle.*\n",
    "\n",
    "8. **Avila, D. (2025).** \"Why Model Context Protocol uses JSON-RPC.\" *Medium*.  \n",
    "   https://medium.com/@dan.avila7/why-model-context-protocol-uses-json-rpc-64d466112338  \n",
    "   *Rationale behind JSON-RPC 2.0 choice and transport flexibility.*\n",
    "\n",
    "9. **IBM.** \"What is Model Context Protocol (MCP)?\"  \n",
    "   https://www.ibm.com/think/topics/model-context-protocol  \n",
    "   *Enterprise perspective on MCP architecture and use cases.*\n",
    "\n",
    "10. **Composio.** \"What is Model Context Protocol (MCP): Explained.\"  \n",
    "    https://composio.dev/blog/what-is-model-context-protocol-mcp-explained  \n",
    "    *Overview of base protocol, lifecycle, and practical examples.*\n",
    "\n",
    "### Related Protocols and Context\n",
    "\n",
    "11. **Microsoft.** \"Language Server Protocol - Overview.\"  \n",
    "    https://microsoft.github.io/language-server-protocol/overviews/lsp/overview/  \n",
    "    *MCP's inspiration - understanding LSP helps understand MCP's design philosophy.*\n",
    "\n",
    "12. **JSON-RPC Working Group.** \"JSON-RPC 2.0 Specification.\"  \n",
    "    https://www.jsonrpc.org/specification  \n",
    "    *The underlying messaging format used by MCP.*\n",
    "\n",
    "### Implementation Libraries\n",
    "\n",
    "13. **Lowin, J.** \"fastmcp - FastAPI for MCP servers.\"  \n",
    "    https://github.com/jlowin/fastmcp  \n",
    "    *Python library used in this notebook's examples.*\n",
    "\n",
    "14. **Anthropic.** \"MCP TypeScript/JavaScript SDK.\"  \n",
    "    https://github.com/modelcontextprotocol/typescript-sdk\n",
    "\n",
    "15. **Anthropic.** \"MCP Python SDK.\"  \n",
    "    https://github.com/modelcontextprotocol/python-sdk\n",
    "\n",
    "### Community Examples\n",
    "\n",
    "16. **Model Context Protocol Servers Repository.**  \n",
    "    https://github.com/modelcontextprotocol/servers  \n",
    "    *Official collection of example MCP servers (filesystem, GitHub, PostgreSQL, etc.)*\n",
    "\n",
    "---\n",
    "\n",
    "### Recommended Reading Order\n",
    "\n",
    "**For beginners:**\n",
    "1. Start with freeCodeCamp article [2] for accessible overview\n",
    "2. Read Lee Hanchung's article [1] for conceptual understanding\n",
    "3. Try the official introduction [3]\n",
    "4. Experiment with fastmcp [13]\n",
    "\n",
    "**For implementers:**\n",
    "1. Official documentation [3-6]\n",
    "2. Technical architecture deep dive [7]\n",
    "3. Implementation SDKs [14-15]\n",
    "4. Community examples [16]\n",
    "\n",
    "**For researchers:**\n",
    "1. Lee Hanchung on design philosophy [1]\n",
    "2. Protocol mechanics [7]\n",
    "3. LSP comparison [11] (to understand the inspiration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
