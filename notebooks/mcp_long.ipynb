{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Model Context Protocol (MCP)\n",
    "**For Computational Linguistics & NLP Students**\n",
    "\n",
    "## 1. What is MCP?\n",
    "\n",
    "In the world of software engineering, connecting different systems usually involves writing custom \"glue code\" for every single connection. If you wanted Claude, ChatGPT, and a local open-source model to all talk to your specific dataset, you would historically have to build three separate integrations.\n",
    "\n",
    "**The Model Context Protocol (MCP)** is an open standard that solves this $m \\times n$ problem. Think of it like a **USB-C port for AI applications**.\n",
    "\n",
    "* **USB-C:** A standard port that lets you plug a mouse, keyboard, or drive into *any* computer without writing a new driver for each specific device.\n",
    "* **MCP:** A standard protocol that lets you plug data (like a text corpus) and tools (like a tokenizer) into *any* LLM application (like Claude Desktop or an IDE) without custom integration code.\n",
    "\n",
    "### Core Concepts\n",
    "MCP breaks interaction down into three primary primitives:\n",
    "\n",
    "1.  **Resources:** Data that the model can read (like files, database rows, or API responses). Think of this as the \"File GET\" capability.\n",
    "2.  **Tools:** Functions that the model can execute (like calculating statistics, running code, or querying a search engine). Think of this as the \"Function Call\" capability.\n",
    "3.  **Prompts:** Pre-defined templates that help users use the server's capabilities effectively.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. MCP vs. RESTful APIs: A Deep Dive\n",
    "\n",
    "As students familiar with backend development (like FastAPI), you are likely used to REST APIs. It is crucial to understand that MCP is not just \"another API style\"; it represents a fundamental shift in **who** the client is and **how** capabilities are discovered.\n",
    "\n",
    "### 2.1 The Philosophical Divide: Actions vs. Resources\n",
    "\n",
    "The most important distinction between MCP and REST is their fundamental design philosophy:\n",
    "\n",
    "**REST APIs are resource-oriented** (focused on nouns):\n",
    "- They model the world as a collection of resources: `GET /blogs`, `POST /users`\n",
    "- They use a fixed set of HTTP verbs (GET, POST, PUT, DELETE) for CRUD operations\n",
    "- Designed for **Human-Computer Interfaces (HCI)**: Developers read documentation and write code\n",
    "\n",
    "**MCP is action-oriented** (focused on verbs):\n",
    "- It models the world as a collection of capabilities: `publishBlog()`, `analyzeText()`\n",
    "- It uses method names that directly express what the agent wants to do\n",
    "- Designed for **Agent-Computer Interfaces (ACI)**: AI models discover and invoke tools\n",
    "\n",
    "### 2.2 Detailed Comparison Table\n",
    "\n",
    "| Feature | REST API | Model Context Protocol (MCP) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Primary User** | A Software Developer (writing code to hit endpoints) | An AI Model (discovering tools to solve problems) |\n",
    "| **Design Philosophy** | Resource-centric (\"What data exists?\") | Action-centric (\"What can I do?\") |\n",
    "| **Discovery** | **Manual**: You read Swagger/OpenAPI docs to know endpoints exist. | **Automatic**: The protocol includes a handshake where the server tells the LLM, \"Here is everything I can do.\" |\n",
    "| **State** | **Stateless** (usually): Each HTTP request is independent. | **Stateful Session**: A persistent connection (JSON-RPC over stdio/SSE) maintains the context lifecycle. |\n",
    "| **Communication** | **HTTP verbs**: GET, POST, PUT, DELETE applied to resources | **RPC Methods**: Direct function calls like `calculateTTR(text)` |\n",
    "| **Semantics** | **Low-level**: \"Update the blog with ID 123\" | **High-level**: \"Archive all old blog posts from 2023\" |\n",
    "| **Error Handling** | HTTP Status Codes (404, 500). | Structured text/JSON that the LLM reads to self-correct (e.g., \"Tool Error: File not found, try listing files first\"). |\n",
    "| **Transactionality** | No built-in support; each request is atomic | Can encapsulate multi-step operations server-side |\n",
    "| **Message Format** | HTTP with various content types | JSON-RPC 2.0 |\n",
    "| **Transport Options** | HTTP/HTTPS only | stdio, Server-Sent Events (SSE), Streamable HTTP, WebSockets |\n",
    "\n",
    "**Key Takeaway:** REST is designed for *rigid, pre-defined* machine-to-machine communication. MCP is designed for *flexible, exploratory* Model-to-Context communication.\n",
    "\n",
    "### 2.3 Why Wrapping REST APIs as MCP is Problematic\n",
    "\n",
    "Many early MCP implementations simply create a thin wrapper over existing REST APIs. This creates what's called an **\"impedance mismatch\"** - a fundamental incompatibility between two design paradigms:\n",
    "\n",
    "**Problem 1: Lost Semantic Meaning**\n",
    "```python\n",
    "# What an agent WANTS to do:\n",
    "archiveOldBlogPosts(beforeDate=\"2023-01-01\")\n",
    "\n",
    "# What a REST wrapper forces it to do:\n",
    "# 1. GET /api/blogs?status=published&beforeDate=2023-01-01\n",
    "# 2. For each blog ID: PUT /api/blogs/{id} with {\"status\": \"archived\"}\n",
    "```\n",
    "The agent loses the high-level \"archive\" action and must orchestrate low-level CRUD operations.\n",
    "\n",
    "**Problem 2: Transactionality Nightmares**\n",
    "Consider `transferBlogPostOwnership(blogId, fromAuthorId, toAuthorId)`. This requires:\n",
    "1. Verifying `fromAuthorId` owns the blog\n",
    "2. Updating the blog's `authorId`\n",
    "3. Logging the transfer\n",
    "\n",
    "With REST, if step 2 fails after step 1, you have an inconsistent state. An RPC can encapsulate this entire logic server-side, ensuring atomicity.\n",
    "\n",
    "**Problem 3: Inefficient, \"Chatty\" Interactions**\n",
    "```python\n",
    "# What an agent wants: increment like count\n",
    "incrementLikeCount(blogId)\n",
    "\n",
    "# What a REST wrapper does:\n",
    "# 1. GET /api/blogs/123  (fetch entire blog object)\n",
    "# 2. Modify like_count locally\n",
    "# 3. PUT /api/blogs/123  (send entire blog object back)\n",
    "```\n",
    "This is wasteful compared to a direct RPC.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Technical Architecture: How MCP Works\n",
    "\n",
    "### 3.1 The Three-Layer Architecture\n",
    "\n",
    "MCP follows a clean three-layer design:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┐\n",
    "│   Protocol Layer (Application Logic)    │\n",
    "│   • MCP Client / MCP Server             │\n",
    "│   • Capability Negotiation              │\n",
    "│   • Tool/Resource/Prompt Management     │\n",
    "└──────────────────┬──────────────────────┘\n",
    "                   │\n",
    "┌──────────────────▼──────────────────────┐\n",
    "│      Session Layer (State Management)   │\n",
    "│   • Connection Lifecycle                │\n",
    "│   • Request/Response Correlation        │\n",
    "│   • Timeout & Error Handling            │\n",
    "└──────────────────┬──────────────────────┘\n",
    "                   │\n",
    "┌──────────────────▼──────────────────────┐\n",
    "│    Transport Layer (Message Delivery)   │\n",
    "│   • JSON-RPC Serialization              │\n",
    "│   • stdio / SSE / HTTP / WebSockets     │\n",
    "│   • Message Framing & Delimiters        │\n",
    "└─────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 3.2 JSON-RPC 2.0: The Message Format\n",
    "\n",
    "At its core, MCP uses **JSON-RPC 2.0** for all communication. This provides three message types:\n",
    "\n",
    "**1. Request (expects a response):**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"method\": \"tools/call\",\n",
    "  \"params\": {\n",
    "    \"name\": \"calculate_ttr\",\n",
    "    \"arguments\": {\n",
    "      \"text\": \"The quick brown fox jumps over the lazy dog.\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**2. Response (reply to a request):**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"result\": {\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"0.89\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**3. Notification (one-way message, no response expected):**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"method\": \"notifications/progress\",\n",
    "  \"params\": {\n",
    "    \"progressToken\": \"token123\",\n",
    "    \"progress\": 50,\n",
    "    \"total\": 100\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Why JSON-RPC?**\n",
    "- **Lightweight**: Minimal overhead compared to SOAP or GraphQL\n",
    "- **Language-agnostic**: JSON is universally supported\n",
    "- **Proven**: Used successfully in Language Server Protocol (LSP) - the inspiration for MCP\n",
    "- **Simple**: Only three message types to understand\n",
    "\n",
    "### 3.3 Transport Options\n",
    "\n",
    "MCP is **transport-agnostic**, supporting multiple communication channels:\n",
    "\n",
    "#### **1. stdio (Standard Input/Output)**\n",
    "- **Use case**: Local integrations where server runs as a subprocess\n",
    "- **How it works**: Client launches server as child process, communicates via stdin/stdout pipes\n",
    "- **Pros**: Simple, low latency, no network overhead\n",
    "- **Cons**: Only works locally\n",
    "- **Example**: A linguistic annotation tool running as a local subprocess\n",
    "\n",
    "#### **2. Server-Sent Events (SSE) + HTTP POST**\n",
    "- **Use case**: Remote servers that need to push updates to clients\n",
    "- **How it works**: \n",
    "  - Client → Server: HTTP POST requests\n",
    "  - Server → Client: SSE stream for continuous updates\n",
    "- **Pros**: Real-time streaming, works through firewalls\n",
    "- **Cons**: One-directional streaming\n",
    "- **Example**: A corpus service that streams new texts as they're added\n",
    "\n",
    "#### **3. Streamable HTTP**\n",
    "- **Use case**: Modern web applications\n",
    "- **How it works**: Bidirectional streaming over HTTP\n",
    "- **Pros**: Stateful sessions, resumable connections\n",
    "- **Cons**: More complex implementation\n",
    "- **Example**: Enterprise-scale NLP services\n",
    "\n",
    "#### **Message Framing**\n",
    "For stdio transport, messages are typically delimited using:\n",
    "```\n",
    "Content-Length: 157\\r\\n\n",
    "\\r\\n\n",
    "{\"jsonrpc\":\"2.0\",\"method\":\"tools/call\",...}\n",
    "```\n",
    "This ensures reliable parsing even when messages are large or arrive in fragments.\n",
    "\n",
    "### 3.4 Connection Lifecycle\n",
    "\n",
    "Every MCP session follows a structured lifecycle:\n",
    "\n",
    "```\n",
    "CLIENT                          SERVER\n",
    "  │                               │\n",
    "  ├──── initialize ──────────────>│  (1) Negotiate capabilities\n",
    "  │<───── capabilities ───────────┤      Client: \"I support sampling\"\n",
    "  │                               │      Server: \"I have tools, resources\"\n",
    "  │                               │\n",
    "  ├──── initialized ─────────────>│  (2) Confirm ready to operate\n",
    "  │                               │\n",
    "  │   ╔═══ ACTIVE SESSION ═══╗   │\n",
    "  │   ║                       ║   │\n",
    "  ├──── tools/list ──────────────>│  (3) Discover available tools\n",
    "  │<───── tool_list ───────────────┤\n",
    "  │                               │\n",
    "  ├──── resources/read ──────────>│  (4) Access data\n",
    "  │<───── resource_content ────────┤\n",
    "  │                               │\n",
    "  ├──── tools/call ──────────────>│  (5) Execute operations\n",
    "  │<───── call_result ─────────────┤\n",
    "  │   ║                       ║   │\n",
    "  │   ╚═══════════════════════╝   │\n",
    "  │                               │\n",
    "  ├──── [close connection] ──────>│  (6) Clean shutdown\n",
    "  │                               │\n",
    "```\n",
    "\n",
    "**Key phases:**\n",
    "1. **Initialization**: Exchange version info and capabilities\n",
    "2. **Discovery**: Client learns what tools/resources are available\n",
    "3. **Operation**: Normal tool calls and resource access\n",
    "4. **Shutdown**: Graceful connection closure\n",
    "\n",
    "---\n",
    "\n",
    "## 4. MCP's Design Principles for AI Agents\n",
    "\n",
    "### 4.1 Design for Actions, Not Data Manipulation\n",
    "\n",
    "When building MCP servers, think about the **goals** an agent wants to achieve, not the data structures.\n",
    "\n",
    "**❌ Bad (REST-style thinking):**\n",
    "```python\n",
    "@mcp.tool()\n",
    "def get_corpus_entry(entry_id: str) -> dict:\n",
    "    \"\"\"Get a corpus entry by ID\"\"\"\n",
    "    return database.get(entry_id)\n",
    "\n",
    "@mcp.tool()\n",
    "def update_corpus_entry(entry_id: str, data: dict) -> dict:\n",
    "    \"\"\"Update a corpus entry\"\"\"\n",
    "    return database.update(entry_id, data)\n",
    "```\n",
    "\n",
    "**✅ Good (Action-oriented thinking):**\n",
    "```python\n",
    "@mcp.tool()\n",
    "def annotate_text_with_pos_tags(text_id: str, tagger: str = \"spacy\") -> str:\n",
    "    \"\"\"Add part-of-speech tags to a text in the corpus.\n",
    "    \n",
    "    Args:\n",
    "        text_id: The ID of the text to annotate\n",
    "        tagger: The POS tagger to use (spacy, nltk, or stanza)\n",
    "    \n",
    "    Returns:\n",
    "        The annotated text with inline POS tags\n",
    "    \"\"\"\n",
    "    text = corpus.get_text(text_id)\n",
    "    tagged = pos_tag(text, tagger=tagger)\n",
    "    corpus.save_annotation(text_id, \"pos\", tagged)\n",
    "    return tagged\n",
    "\n",
    "@mcp.tool()\n",
    "def find_texts_by_lexical_complexity(\n",
    "    min_ttr: float, \n",
    "    max_ttr: float\n",
    ") -> list[str]:\n",
    "    \"\"\"Find corpus texts within a TTR range.\n",
    "    \n",
    "    Returns:\n",
    "        List of text IDs matching the complexity criteria\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for text_id in corpus.list_ids():\n",
    "        text = corpus.get_text(text_id)\n",
    "        ttr = calculate_ttr(text)\n",
    "        if min_ttr <= ttr <= max_ttr:\n",
    "            results.append(text_id)\n",
    "    return results\n",
    "```\n",
    "\n",
    "Notice how the good examples:\n",
    "- Express **what the agent wants to accomplish** (\"annotate with POS tags\", \"find by complexity\")\n",
    "- Encapsulate **domain logic** (choosing a tagger, calculating TTR)\n",
    "- Handle **multi-step operations** atomically\n",
    "\n",
    "### 4.2 Safety and Security in MCP\n",
    "\n",
    "One of MCP's key advantages over letting models call APIs directly is **controlled access**:\n",
    "\n",
    "**1. Secret Management**\n",
    "```python\n",
    "import os\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"SecureCorpus\")\n",
    "\n",
    "@mcp.tool()\n",
    "def query_proprietary_corpus(query: str) -> str:\n",
    "    \"\"\"Search our proprietary corpus (requires authentication).\"\"\"\n",
    "    # API key is stored server-side - model never sees it\n",
    "    api_key = os.environ[\"CORPUS_API_KEY\"]\n",
    "    return corpus_api.search(query, api_key=api_key)\n",
    "```\n",
    "The LLM only sees `query_proprietary_corpus(\"syntax trees\")` - it never has access to credentials.\n",
    "\n",
    "**2. Input Validation**\n",
    "```python\n",
    "@mcp.tool()\n",
    "def delete_annotation(\n",
    "    text_id: str, \n",
    "    annotation_type: str\n",
    ") -> str:\n",
    "    \"\"\"Delete an annotation from a text.\"\"\"\n",
    "    # Validate inputs before executing destructive operations\n",
    "    if annotation_type not in [\"pos\", \"ner\", \"dependency\"]:\n",
    "        return \"Error: Invalid annotation type. Must be pos, ner, or dependency.\"\n",
    "    \n",
    "    if not corpus.text_exists(text_id):\n",
    "        return f\"Error: Text {text_id} not found.\"\n",
    "    \n",
    "    corpus.delete_annotation(text_id, annotation_type)\n",
    "    return f\"Successfully deleted {annotation_type} annotation from {text_id}\"\n",
    "```\n",
    "\n",
    "**3. Rate Limiting and Auditing**\n",
    "```python\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@mcp.tool()\n",
    "def run_expensive_analysis(text_id: str) -> dict:\n",
    "    \"\"\"Run computationally expensive linguistic analysis.\"\"\"\n",
    "    # Log all tool invocations for audit trail\n",
    "    logger.info(f\"[{datetime.now()}] Expensive analysis requested for {text_id}\")\n",
    "    \n",
    "    # Implement rate limiting\n",
    "    if not rate_limiter.check_quota():\n",
    "        return {\"error\": \"Rate limit exceeded. Try again in 1 hour.\"}\n",
    "    \n",
    "    return perform_analysis(text_id)\n",
    "```\n",
    "\n",
    "**4. Sandboxing and Permissions**\n",
    "MCP servers can run with restricted file system access:\n",
    "```python\n",
    "# Server only has read access to /data/corpus/\n",
    "# Cannot access /etc/ or other sensitive directories\n",
    "@mcp.resource(\"corpus://text/{text_id}\")\n",
    "def get_text(text_id: str) -> str:\n",
    "    # Path is constrained to safe directory\n",
    "    safe_path = CORPUS_DIR / f\"{text_id}.txt\"\n",
    "    if not safe_path.exists():\n",
    "        return \"Error: Text not found\"\n",
    "    return safe_path.read_text()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Demo: A \"Linguist's Helper\" MCP Server\n",
    "\n",
    "We will use `fastmcp`, a Python library that makes building MCP servers as easy as writing FastAPI applications. \n",
    "\n",
    "In this demo, we simulate a server that manages a small linguistic corpus. It provides:\n",
    "1.  **A Resource** allowing the LLM to read texts.\n",
    "2.  **A Tool** allowing the LLM to calculate the **Type-Token Ratio (TTR)**, a measure of vocabulary variation.\n",
    "3.  **A Prompt** helping the user analyze the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ensure you have the library installed\n",
    "# %pip install fastmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "# 1. Initialize the Server\n",
    "# This is analogous to `app = FastAPI()`\n",
    "mcp = FastMCP(\"LinguistHelper\")\n",
    "\n",
    "# --- Mock Data Layer ---\n",
    "# In a real app, this might be a database or a directory of .txt files\n",
    "CORPUS = {\n",
    "    \"en_sample_01\": \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"en_sample_02\": \"To be, or not to be, that is the question.\",\n",
    "    \"zh_sample_01\": \"學而不思則罔,思而不學則殆。\"  # \"Learning without thought is labor lost...\"\n",
    "}\n",
    "\n",
    "# --- RESOURCES: Data Retrieval ---\n",
    "\n",
    "@mcp.resource(\"corpus://{text_id}\")\n",
    "def get_text(text_id: str) -> str:\n",
    "    \"\"\"Retrieve raw text content from the corpus by its ID.\"\"\"\n",
    "    return CORPUS.get(text_id, \"Error: Text ID not found in corpus.\")\n",
    "\n",
    "@mcp.resource(\"corpus://list\")\n",
    "def list_texts() -> str:\n",
    "    \"\"\"List all available text IDs in the corpus.\"\"\"\n",
    "    return \"\\n\".join(CORPUS.keys())\n",
    "\n",
    "# --- TOOLS: Computational Functions ---\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_ttr(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Type-Token Ratio (TTR) of a text string.\n",
    "    TTR = (Unique Words / Total Words). \n",
    "    Higher TTR indicates greater lexical diversity.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    \n",
    "    # Simple whitespace tokenization for demo purposes\n",
    "    # In a real NLP app, we would use spaCy or NLTK here\n",
    "    tokens = text.lower().split()\n",
    "    types = set(tokens)\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    return len(types) / len(tokens)\n",
    "\n",
    "# --- PROMPTS: Pre-defined workflows ---\n",
    "\n",
    "@mcp.prompt()\n",
    "def analyze_text_complexity(text_id: str) -> str:\n",
    "    \"\"\"Create a prompt to guide the LLM in analyzing a text's complexity.\"\"\"\n",
    "    return f\"Please analyze the linguistic complexity of the text located at corpus://{text_id}. First, use the 'calculate_ttr' tool to find its Type-Token Ratio. Then, review the content and explain if the TTR score matches your qualitative assessment of the vocabulary.\"\n",
    "\n",
    "# --- Running the Server ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # In a real deployment, this runs a loop listening for connections.\n",
    "    # For a notebook demo, we simply define the server.\n",
    "    # You would typically run this script via terminal: `fastmcp run my_script.py`\n",
    "    print(\"MCP Server 'LinguistHelper' defined successfully.\")\n",
    "    print(\"Resources:\", mcp._resource_manager._resources.keys())\n",
    "    print(\"Tools:\", mcp._tool_manager._tools.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How It Works Under the Hood\n",
    "\n",
    "When you connect an LLM client (like Claude Desktop) to this script:\n",
    "\n",
    "### Step-by-Step Execution Flow\n",
    "\n",
    "**1. Connection & Initialization**\n",
    "```json\n",
    "// Client sends:\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"method\": \"initialize\",\n",
    "  \"params\": {\n",
    "    \"protocolVersion\": \"2024-11-05\",\n",
    "    \"capabilities\": {\"sampling\": {}},\n",
    "    \"clientInfo\": {\"name\": \"Claude\", \"version\": \"1.0\"}\n",
    "  }\n",
    "}\n",
    "\n",
    "// Server responds:\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"result\": {\n",
    "    \"protocolVersion\": \"2024-11-05\",\n",
    "    \"capabilities\": {\n",
    "      \"tools\": {},\n",
    "      \"resources\": {\"subscribe\": false}\n",
    "    },\n",
    "    \"serverInfo\": {\"name\": \"LinguistHelper\", \"version\": \"1.0\"}\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**2. Tool Discovery**\n",
    "```json\n",
    "// Client: \"What can you do?\"\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 2,\n",
    "  \"method\": \"tools/list\"\n",
    "}\n",
    "\n",
    "// Server: \"Here are my capabilities\"\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 2,\n",
    "  \"result\": {\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"name\": \"calculate_ttr\",\n",
    "        \"description\": \"Calculate the Type-Token Ratio (TTR)...\",\n",
    "        \"inputSchema\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"text\": {\"type\": \"string\"}\n",
    "          },\n",
    "          \"required\": [\"text\"]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**3. User Query & Tool Execution**\n",
    "\n",
    "User asks: *\"Is 'en_sample_01' lexically diverse?\"*\n",
    "\n",
    "The LLM reasons:\n",
    "1. \"I need to read the text first\" → Calls `resources/read`\n",
    "2. \"I need to calculate TTR\" → Calls `tools/call` with `calculate_ttr`\n",
    "3. \"Now I can answer\" → Generates response with context\n",
    "\n",
    "```json\n",
    "// Reading the resource\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 3,\n",
    "  \"method\": \"resources/read\",\n",
    "  \"params\": {\"uri\": \"corpus://en_sample_01\"}\n",
    "}\n",
    "\n",
    "// Server returns text\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 3,\n",
    "  \"result\": {\n",
    "    \"contents\": [\n",
    "      {\n",
    "        \"uri\": \"corpus://en_sample_01\",\n",
    "        \"mimeType\": \"text/plain\",\n",
    "        \"text\": \"The quick brown fox jumps over the lazy dog.\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "// Calling the tool\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 4,\n",
    "  \"method\": \"tools/call\",\n",
    "  \"params\": {\n",
    "    \"name\": \"calculate_ttr\",\n",
    "    \"arguments\": {\n",
    "      \"text\": \"The quick brown fox jumps over the lazy dog.\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// Server returns result\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 4,\n",
    "  \"result\": {\n",
    "    \"content\": [\n",
    "      {\"type\": \"text\", \"text\": \"0.89\"}\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This pattern allows you to inject complex Python logic (tokenization, dependency parsing, vector retrieval) into the AI's workflow essentially for free.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Advanced MCP Patterns for Linguistics Research\n",
    "\n",
    "### 7.1 Multi-Tool Workflows\n",
    "\n",
    "MCP shines when tools build on each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp_advanced = FastMCP(\"AdvancedLinguistics\")\n",
    "\n",
    "@mcp_advanced.tool()\n",
    "def tokenize_text(text: str, language: str = \"en\") -> list[str]:\n",
    "    \"\"\"Tokenize text using language-specific rules.\"\"\"\n",
    "    # In reality, you'd use spaCy or similar\n",
    "    return text.split()\n",
    "\n",
    "@mcp_advanced.tool()\n",
    "def pos_tag(tokens: list[str], language: str = \"en\") -> list[tuple[str, str]]:\n",
    "    \"\"\"Apply part-of-speech tagging to tokens.\"\"\"\n",
    "    # Dummy implementation - use spaCy in production\n",
    "    return [(token, \"NOUN\") for token in tokens]\n",
    "\n",
    "@mcp_advanced.tool()\n",
    "def extract_noun_phrases(pos_tagged: list[tuple[str, str]]) -> list[str]:\n",
    "    \"\"\"Extract noun phrases from POS-tagged tokens.\"\"\"\n",
    "    return [word for word, tag in pos_tagged if tag.startswith(\"N\")]\n",
    "\n",
    "@mcp_advanced.tool()\n",
    "def full_linguistic_pipeline(\n",
    "    text: str, \n",
    "    language: str = \"en\"\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Run complete linguistic analysis pipeline.\n",
    "    \n",
    "    This demonstrates how to compose multiple tools into a \n",
    "    high-level action that an agent can use atomically.\n",
    "    \"\"\"\n",
    "    tokens = tokenize_text(text, language)\n",
    "    pos_tags = pos_tag(tokens, language)\n",
    "    noun_phrases = extract_noun_phrases(pos_tags)\n",
    "    \n",
    "    return {\n",
    "        \"token_count\": len(tokens),\n",
    "        \"noun_phrases\": noun_phrases,\n",
    "        \"pos_distribution\": {\n",
    "            tag: sum(1 for _, t in pos_tags if t == tag)\n",
    "            for _, tag in pos_tags\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key insight**: The agent can either call tools individually for fine-grained control, or use `full_linguistic_pipeline()` for a complete analysis. This flexibility is MCP's strength.\n",
    "\n",
    "### 7.2 Dynamic Resources\n",
    "\n",
    "Resources don't have to be static files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mcp_advanced.resource(\"corpus://search?query={query}\")\n",
    "def search_corpus(query: str) -> str:\n",
    "    \"\"\"Search the corpus and return matching texts.\n",
    "    \n",
    "    This demonstrates a DYNAMIC resource - the URI contains\n",
    "    query parameters that affect what data is returned.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for text_id, text in CORPUS.items():\n",
    "        if query.lower() in text.lower():\n",
    "            results.append(f\"[{text_id}] {text}\")\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No texts found matching '{query}'\"\n",
    "    \n",
    "    return \"\\n\\n\".join(results)\n",
    "\n",
    "@mcp_advanced.resource(\"corpus://stats/ttr_distribution\")\n",
    "def get_ttr_distribution() -> str:\n",
    "    \"\"\"Get TTR statistics across the entire corpus.\n",
    "    \n",
    "    This demonstrates a COMPUTED resource - the data doesn't\n",
    "    exist as a file but is calculated on-demand.\n",
    "    \"\"\"\n",
    "    ttrs = {}\n",
    "    for text_id, text in CORPUS.items():\n",
    "        ttrs[text_id] = calculate_ttr(text)\n",
    "    \n",
    "    avg_ttr = sum(ttrs.values()) / len(ttrs)\n",
    "    \n",
    "    report = f\"Average TTR: {avg_ttr:.3f}\\n\\n\"\n",
    "    report += \"Per-text breakdown:\\n\"\n",
    "    for text_id, ttr in sorted(ttrs.items(), key=lambda x: x[1], reverse=True):\n",
    "        report += f\"  {text_id}: {ttr:.3f}\\n\"\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Error Handling and Self-Correction\n",
    "\n",
    "MCP's text-based error messages allow LLMs to self-correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mcp_advanced.tool()\n",
    "def calculate_ngram_frequency(\n",
    "    text_id: str, \n",
    "    n: int,\n",
    "    top_k: int = 10\n",
    ") -> dict[str, int] | str:\n",
    "    \"\"\"Calculate n-gram frequencies for a text.\n",
    "    \n",
    "    Args:\n",
    "        text_id: ID of text in corpus\n",
    "        n: Size of n-grams (1=unigrams, 2=bigrams, etc.)\n",
    "        top_k: Number of most frequent n-grams to return\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of n-grams and their counts, or error message\n",
    "    \"\"\"\n",
    "    # Extensive error checking with helpful messages\n",
    "    if text_id not in CORPUS:\n",
    "        available = \", \".join(CORPUS.keys())\n",
    "        return f\"Error: Text '{text_id}' not found. Available texts: {available}\"\n",
    "    \n",
    "    if n < 1 or n > 5:\n",
    "        return \"Error: n must be between 1 and 5. Did you mean n=2 for bigrams?\"\n",
    "    \n",
    "    if top_k < 1:\n",
    "        return \"Error: top_k must be at least 1\"\n",
    "    \n",
    "    text = CORPUS[text_id]\n",
    "    tokens = text.lower().split()\n",
    "    \n",
    "    if len(tokens) < n:\n",
    "        return f\"Error: Text has only {len(tokens)} tokens, cannot create {n}-grams\"\n",
    "    \n",
    "    # Calculate n-grams\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngrams.append(\" \".join(tokens[i:i+n]))\n",
    "    \n",
    "    # Count frequencies\n",
    "    from collections import Counter\n",
    "    freq = Counter(ngrams)\n",
    "    \n",
    "    return dict(freq.most_common(top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the LLM makes a mistake (e.g., passing an invalid `text_id`), it receives a clear error message explaining what went wrong and what the valid options are. This allows it to retry with corrected parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Comparison with Related Technologies\n",
    "\n",
    "### MCP vs. Function Calling APIs\n",
    "\n",
    "Many LLM providers (OpenAI, Anthropic, Google) offer \"function calling\" APIs. How is MCP different?\n",
    "\n",
    "| Aspect | Function Calling APIs | MCP |\n",
    "|--------|----------------------|-----|\n",
    "| **Scope** | Single LLM provider | Universal standard across providers |\n",
    "| **Server** | Developer implements execution | Standardized MCP server with lifecycle |\n",
    "| **Discovery** | Functions defined per-request | Server advertises capabilities |\n",
    "| **State** | Stateless (per request) | Stateful sessions |\n",
    "| **Transport** | HTTP only | stdio, SSE, HTTP, WebSockets |\n",
    "| **Analogy** | Like inline assembly | Like a library with a well-defined API |\n",
    "\n",
    "**Function calling** is great for one-off tool use. **MCP** is designed for building complex, stateful integrations.\n",
    "\n",
    "### MCP vs. LangChain Tools\n",
    "\n",
    "LangChain provides a `Tool` abstraction. MCP takes this further:\n",
    "\n",
    "- **LangChain**: Python-specific, tightly coupled to LangChain framework\n",
    "- **MCP**: Language-agnostic protocol, works with any client\n",
    "- **LangChain**: Tools are Python functions\n",
    "- **MCP**: Tools are network services (can be in any language)\n",
    "\n",
    "Think of MCP as \"LangChain Tools, but as a protocol instead of a library.\"\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Real-World Use Cases in Computational Linguistics\n",
    "\n",
    "### 9.1 Linguistic Fieldwork Assistant\n",
    "```python\n",
    "# MCP server for eliciting grammatical data\n",
    "@mcp.tool()\n",
    "def generate_elicitation_prompt(phenomenon: str, language: str) -> str:\n",
    "    \"\"\"Generate targeted prompts for linguistic fieldwork.\"\"\"\n",
    "    pass\n",
    "\n",
    "@mcp.tool()\n",
    "def analyze_response_for_pattern(\n",
    "    response: str, \n",
    "    expected_pattern: str\n",
    ") -> dict:\n",
    "    \"\"\"Check if speaker's response matches expected grammatical pattern.\"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 9.2 Cross-Linguistic Database Access\n",
    "```python\n",
    "@mcp.resource(\"wals://feature/{feature_id}/languages\")\n",
    "def get_wals_languages(feature_id: str) -> str:\n",
    "    \"\"\"Access WALS database for typological features.\"\"\"\n",
    "    pass\n",
    "\n",
    "@mcp.tool()\n",
    "def find_typologically_similar_languages(\n",
    "    reference_language: str,\n",
    "    features: list[str]\n",
    ") -> list[str]:\n",
    "    \"\"\"Find languages with similar typological profiles.\"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 9.3 Corpus Annotation Pipeline\n",
    "```python\n",
    "@mcp.tool()\n",
    "def run_annotation_pipeline(\n",
    "    text_id: str,\n",
    "    annotations: list[str]  # [\"tokenize\", \"pos\", \"parse\", \"ner\"]\n",
    ") -> str:\n",
    "    \"\"\"Run multiple annotation steps atomically.\"\"\"\n",
    "    pass\n",
    "\n",
    "@mcp.resource(\"corpus://{text_id}/annotations/{layer}\")\n",
    "def get_annotation_layer(text_id: str, layer: str) -> str:\n",
    "    \"\"\"Retrieve specific annotation layer (pos, parse, ner, etc.).\"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Summary: Key Takeaways\n",
    "\n",
    "1. **MCP is NOT just another API format** - it's a paradigm shift from resource-oriented (REST) to action-oriented (RPC) design for AI agents.\n",
    "\n",
    "2. **MCP solves the M×N integration problem** - write one MCP server, use it with any MCP-compatible client (Claude, Cursor, custom tools).\n",
    "\n",
    "3. **MCP uses JSON-RPC 2.0** for messaging, with support for multiple transports (stdio, SSE, HTTP).\n",
    "\n",
    "4. **The three-layer architecture** (Protocol → Session → Transport) keeps concerns separated and implementations clean.\n",
    "\n",
    "5. **Design for actions, not CRUD** - think about what agents want to accomplish, not how to manipulate data structures.\n",
    "\n",
    "6. **Security is built-in** - credentials stay server-side, input validation happens before execution, and audit logging is straightforward.\n",
    "\n",
    "7. **MCP enables composable workflows** - tools can build on each other, resources can be dynamic, and the protocol supports self-correction.\n",
    "\n",
    "8. **For linguistics research**, MCP opens possibilities for corpus access, annotation pipelines, typological databases, and fieldwork assistance.\n",
    "\n",
    "### Further Reading\n",
    "- Official MCP Documentation: https://modelcontextprotocol.io/\n",
    "- fastmcp Python library: https://github.com/jlowin/fastmcp\n",
    "- Language Server Protocol (LSP): https://microsoft.github.io/language-server-protocol/\n",
    "- JSON-RPC 2.0 Specification: https://www.jsonrpc.org/specification\n",
    "\n",
    "### Exercise Ideas\n",
    "1. Extend the demo server to work with a real corpus (e.g., Universal Dependencies)\n",
    "2. Add tools for phonological analysis (syllable counting, stress patterns)\n",
    "3. Create a prompt that guides the LLM through comparative linguistic analysis\n",
    "4. Implement resource subscriptions for real-time corpus updates\n",
    "5. Build an MCP server that interfaces with the Leipzig Glossing Rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
